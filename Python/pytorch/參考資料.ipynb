{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57d04bb-255d-4e3c-aad9-cc34d1e7c34c",
   "metadata": {},
   "source": [
    "* ML的整個「訓練過程」：這裡以監督式學習(Supervised Learning)為例\n",
    "\n",
    "| 階段 | 要做的事情 | 簡介 |\n",
    "| :--: | :--: | -- |\n",
    "| (訓練前) | 決定資料集與分析資料 | 你想要預測的是什麼資料? 這邊需要先知道 example、label、features的概念。介紹可參考：[【Day 15】](https://ithelp.ithome.com.tw/articles/10215499)，而我們這次作為範例的訓練資料集介紹在[【Day 19】](https://ithelp.ithome.com.tw/articles/10217666)。 |\n",
    "| (訓練前) | 決定問題種類 | 依據資料，會知道是什麼類型的問題。regression problem(回歸問題)? classification problem(分類問題)? 此處可參考：[【Day 16】](https://ithelp.ithome.com.tw/articles/10216585)、與進階內容：[【Day 17】](https://ithelp.ithome.com.tw/articles/10215946) |\n",
    "| (訓練前) | 決定ML模型(ML models) | 依據問題的種類，會知道需要使用什麼對應的ML模型。回歸模型(Regression model)? 分類模型(Classification model)? 此處可參考：[【Day 18】](https://ithelp.ithome.com.tw/articles/10217431)，神經網路(neural network)? 簡介於：[【Day 25】](https://ithelp.ithome.com.tw/articles/10221227) |\n",
    "| | (模型裡面的參數) | ML模型裡面的參數(parameters)與超參數(hyper-parameters) 此處可參考：[【Day 18】](https://ithelp.ithome.com.tw/articles/10217431) |\n",
    "| (訓練中)<br>調整模型 | 評估當前模型好壞 | 損失函數(Loss Functions)：使用損失函數評估目前模型的好與壞。以MSE(Mean Squared Error), RMSE(Root Mean Squared Error), 交叉熵(Cross Entropy)為例。此處可參考：[【Day 20】](https://ithelp.ithome.com.tw/articles/10218158) |\n",
    "| (訓練中)<br>調整模型 | 修正模型參數 | 以梯度下降法 (Gradient Descent)為例：決定模型中參數的修正「方向」與「步長(step size)」此處可參考：[【Day 21】](https://ithelp.ithome.com.tw/articles/10218980) |\n",
    "| (訓練中)<br>調整腳步 | 調整學習腳步 | 透過學習速率(learning rate)來調整ML模型訓練的步長(step size)，調整學習腳步。(此參數在訓練前設定，為hyper-parameter)。此處可參考：[【Day 22】](https://ithelp.ithome.com.tw/articles/10219458) |\n",
    "| (訓練中)<br>加快訓練 | 取樣與分堆 | 設定batch size，透過batch從訓練目標中取樣，來加快ML模型訓練的速度。(此參數在訓練前設定，為hyper-parameter)。與迭代(iteration),epoch介紹。此處可參考：[【Day 23】](https://ithelp.ithome.com.tw/articles/10219945/draft) |\n",
    "| (訓練中)<br>加快訓練 | 檢查loss的頻率 | 調整「檢查loss的頻率」，依據時間(Time-based)與步驟(Step-based)。此處可參考：[【Day 23】](https://ithelp.ithome.com.tw/articles/10219945/draft) |\n",
    "| (訓練中)<br>完成訓練 | (loop) -> 完成 | 重覆過程(評估當前模型好壞 -> 修正模型參數)，直到能通過「驗證資料集(Validation)」的驗證即可結束訓練。此處可參考：[【Day 27】](https://ithelp.ithome.com.tw/articles/10222043) |\n",
    "| (訓練後) | 訓練結果可能問題 | 「不適當的最小loss?」 此處可參考：[【Day 28】](https://ithelp.ithome.com.tw/articles/10222317) |\n",
    "| (訓練後) | 訓練結果可能問題 | 欠擬合(underfitting)?過度擬合(overfitting)? 此處可參考：[【Day 26】](https://ithelp.ithome.com.tw/articles/10221245) |\n",
    "| (訓練後) | 評估 - 性能指標 | 性能指標(performance metrics)：以混淆矩陣(confusion matrix)分析，包含「Accuracy」、「Precision」、「Recall」三種評估指標。簡介於：[【Day 28】](https://ithelp.ithome.com.tw/articles/10222317)、詳細介紹於：[【Day 29】](https://ithelp.ithome.com.tw/articles/10222697) |\n",
    "| (訓練後) | 評估 - 新資料適用性 | 泛化(Generalization)：對於新資料、沒看過的資料的模型適用性。此處可參考：[【Day 26】](https://ithelp.ithome.com.tw/articles/10221245) |\n",
    "| (訓練後) | 評估 - 模型測試 | 使用「獨立測試資料集(Test)」測試? 使用交叉驗證(cross-validation)(又稱bootstrapping)測試? 此處可參考：[【Day 27】](https://ithelp.ithome.com.tw/articles/10222043) |\n",
    "| | (資料分堆的方式) | (訓練前) 依據上方「模型測試」的方法，決定資料分堆的方式：訓練用(Training)、驗證用(Validation)、測試用(Test)。此處可參考：[【Day 27】](https://ithelp.ithome.com.tw/articles/10222043) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6462b50-6b2e-47b5-84a8-0a79477c2eba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 範例資料集\n",
    "\n",
    "* [Kaggle: Your Home for Data Science](https://www.kaggle.com/)  \n",
    "* [Gender Classification Dataset | Kaggle](https://www.kaggle.com/datasets/elakiricoder/gender-classification-dataset)\n",
    "* * *\n",
    "#### Python 觀念\n",
    "1. [Python基礎功不可少-dir()與help()的使用 @ 布萊恩的創業小窩的部落格 :: 痞客邦 ::](https://kobebrian5778.pixnet.net/blog/post/308583806-python%E5%9F%BA%E7%A4%8E%E5%8A%9F%E4%B8%8D%E5%8F%AF%E5%B0%91-dir%28%29%E8%88%87help%28%29%E7%9A%84%E4%BD%BF%E7%94%A8)\n",
    "2. [Python help() 函數 |  數字海洋](https://www.digitalocean.com/community/tutorials/python-help-function)  \n",
    "3. [Python enumerate() 函数 | 菜鸟教程](https://www.runoob.com/python/python-func-enumerate.html)  \n",
    "4. [How to Write Beautiful Python Code With PEP 8 – Real Python](https://realpython.com/python-pep8/#naming-styles)\n",
    "* * *\n",
    "#### Git 觀念\n",
    "1. [Git Commit Message Standard](https://gist.github.com/tonibardina/9290fbc7d605b4f86919426e614fe692)\n",
    "2. [Git Commit Message 這樣寫會更好，替專案引入規範與範例](https://wadehuanglearning.blogspot.com/2019/05/commit-commit-commit-why-what-commit.html)\n",
    "3. [Git - git-restore Documentation](https://git-scm.com/docs/git-restore)\n",
    "4. [菜鳥工程師 肉豬: Git 復原已staged的檔案 unstage changing Files](https://matthung0807.blogspot.com/2019/09/git-unstage-changing-files.html)\n",
    "5. [git操作之二：git restore - 良工说技术 - 博客园](https://www.cnblogs.com/teach/p/13997323.html)\n",
    "6. [檔案的四種狀態 · GIT教學](https://kingofamani.gitbooks.io/git-teach/content/chapter_2/repo.html)\n",
    "7. [檔案狀態 · Git](https://zlargon.gitbooks.io/git-tutorial/content/file/status.html)\n",
    "* * *\n",
    "#### PyTorch\n",
    "\n",
    "1. [Quickstart — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "2. [Datasets & DataLoaders — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "3. [Build the Neural Network — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "4. [Optimizing Model Parameters — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)\n",
    "5. [Save and Load the Model — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)\n",
    "* * *\n",
    "#### Markdown\n",
    "\n",
    "1. [如何建立表格 - HackMD](https://hackmd.io/c/tutorials-tw/%2Fs%2Fhow-to-create-table-tw)  \n",
    "2. [[教學] 撰寫 Hexo 文章 - Markdown 語法大全 | 瑪利歐的部落格](https://ed521.github.io/2019/08/hexo-markdown/)  \n",
    "3. [Markdown 表格 | 菜鸟教程](https://www.runoob.com/markdown/md-table.html)\n",
    "* * *\n",
    "#### ML 學習資源\n",
    "\n",
    "* 建議參考此網頁的 ML的整個訓練過程  \n",
    "[【Day 19】 Google ML - Lesson 5 - 接下來幾天作為範例的「訓練資料集介紹」、範例「資料集訓練前分析」(順便補上整個ML訓練流程，作為系列文章中的訓練階段參考) - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10217666?sc=rss.iron)  \n",
    "\n",
    "1. [零基礎自學深度學習 ：（一）神經網路基本架構. 筆者曾於Coursera觀看過臺灣大學資工系林軒田教授授課的「機器學習基石（Ma… | by Evan | Medium](https://evan-hsiao.medium.com/%E5%BE%9Ecoursera%E5%AD%B8%E7%BF%92%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-bd6bad6f5e14)\n",
    "2. [Day-21 實際重現神經元是可做到的嗎? Feed-Forward Neural Network Building - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10277989)\n",
    "3. [[Day 29] Deep learning -- 各種模型(i) - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10189072)\n",
    "4. [DAY18：激活函數 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10276865)\n",
    "5. [Day-19 PyTorch 怎麼讀取資料? Dataset and DataLoader - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10277163)\n",
    "6. [【12】新手容易忽略的 logit 與 loss 之間的搭配 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10272449)\n",
    "7. [機器/深度學習: 基礎介紹-損失函數(loss function) | by Tommy Huang | Medium](https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E4%BB%8B%E7%B4%B9-%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-loss-function-2dcac5ebb6cb)\n",
    "8. [【Day 20】 Google ML - Lesson 6 - 使用損失函數(Loss Functions)來評估ML模型的好壞吧!  MSE, RMSE, Cross Entropy的計算方法與特性 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10218158)\n",
    "9. [Day 14 Optimizer大亂鬥 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10236554)\n",
    "10. [[機器學習ML NOTE]SGD, Momentum, AdaGrad, Adam Optimizer | by GGWithRabitLIFE | 雞雞與兔兔的工程世界 | Medium](https://medium.com/%E9%9B%9E%E9%9B%9E%E8%88%87%E5%85%94%E5%85%94%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%B8%96%E7%95%8C/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92ml-note-sgd-momentum-adagrad-adam-optimizer-f20568c968db)\n",
    "11. [7 Types of Classification Algorithms](https://analyticsindiamag.com/7-types-classification-algorithms/)\n",
    "12. [【Day 18】 Google ML - Lesson 4 - 什麼是ML模型?訓練的目標? 回歸模型(Regression model), 分類模型(Classification model)的運算 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10217431)\n",
    "13. [【大數據小知識】什麼是分類模型 (Classification)？如何評估 (Evaluate) 分類模型？ | by 資料分析大小事 | Taiwanese in Data Science | Medium](https://medium.com/women-in-data-science-taipei/%E5%A4%A7%E6%95%B8%E6%93%9A%E5%B0%8F%E7%9F%A5%E8%AD%98-%E4%BB%80%E9%BA%BC%E6%98%AF%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B-classification-%E5%A6%82%E4%BD%95%E8%A9%95%E4%BC%B0-evaluate-%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B-a96143d9a493)\n",
    "14. [The Neural Network Zoo - The Asimov Institute](https://www.asimovinstitute.org/neural-network-zoo/)  \n",
    "15. [bearpaw/pytorch-classification: Classification with PyTorch.](https://github.com/bearpaw/pytorch-classification)  \n",
    "16. [Use PyTorch to train your image classification model | Microsoft Learn](https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-train-model)  \n",
    "17. [主流的深度学习模型有哪些？ - 知乎](https://zhuanlan.zhihu.com/p/29769502)  \n",
    "18. [【機器學習從零到一】 Day3: Pytorch 介紹與範例 (cosmetics classification) | by PJ Wang | Medium](https://daniel820710.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%BE%9E%E9%9B%B6%E5%88%B0%E4%B8%80-day3-pytorch-%E4%BB%8B%E7%B4%B9%E8%88%87%E7%AF%84%E4%BE%8B-cosmetics-classification-6e826fbce59b)  \n",
    "19. [【機器學習懶人包】從數據分析到模型整合，各種好用的演算法全都整理給你啦！ | TechOrange 科技報橘](https://buzzorange.com/techorange/2019/08/13/machine-learning-algorithm-collection/)  \n",
    "20. [機器學習入門——常用優化器(Optimizer)的種類與選擇 - 程式人生](https://www.796t.com/content/1545433422.html)\n",
    "21. [Day 02：撰寫第一支 Neural Network 程式 -- 阿拉伯數字辨識 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10191404)\n",
    "22. [[Day8]資料正規化(Normalization)與標準化(Standardization) - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10293893)\n",
    "23. [[Day 27] 機器學習常犯錯的十件事 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10279778)\n",
    "24. [[Day 3] 你真了解資料嗎？試試看視覺化分析吧！ - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10264416)\n",
    "25. [Day 6. 機器學習模型 - 學習的種類 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10295354)\n",
    "26. [[精進魔法]  Optimization：優化深度學習模型的技巧（上） - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10203542)\n",
    "27. [[精進魔法]  Optimization：優化深度學習模型的技巧（中）－ Adaptive Learning Rates - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10204032)\n",
    "28. [[精進魔法]  Optimization：優化深度學習模型的技巧（下）－ Batch Normalization - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10204106)\n",
    "29. [使用openpose计算人体骨骼角度_51CTO博客_openpose人体轮廓](https://blog.51cto.com/u_15279692/2941318)\n",
    "30. [tfjs-models/tree/master/pose-detection](https://github.com/tensorflow/tfjs-models/tree/master/pose-detection)\n",
    "31. [Find the Angle between three points from 2D using python | by Manivannan Murugavel | Medium](https://manivannan-ai.medium.com/find-the-angle-between-three-points-from-2d-using-python-348c513e2cd)\n",
    "32. [怎么快速求出三点之间的夹角？-CSDN社区](https://bbs.csdn.net/topics/80181427)\n",
    "33. [平面三点计算夹角_计算三点之间的夹角_MobileCSD的博客-CSDN博客](https://blog.csdn.net/zhang1244j/article/details/55053184)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb64c88-0dc0-45a5-8dcd-1f839188339c",
   "metadata": {},
   "source": [
    "weighted 數量: (input size +1) * hidden size....."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
