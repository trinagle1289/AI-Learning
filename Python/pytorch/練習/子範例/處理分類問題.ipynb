{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701fb43c-4310-4127-a7ae-caf619ceb1a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 處理分類問題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20349c97-3602-4b62-850c-f6d579edb261",
   "metadata": {},
   "source": [
    "主要流程:  \n",
    "1. 讀取 CSV 資料並建立資料集\n",
    "    1. 使用 pandas 套件讀取 CSV 檔案資料\n",
    "    2. 使用 torch.data.utils.Dataset 存取 pandas 所讀取的資料\n",
    "2. 將資料轉換成 PyTorch 容易使用的資料\n",
    "    * 使用 torch.data.utils.DataLoader 將 Dataset 的資料轉化成機器學習容易使用的格式\n",
    "3. 建立用於分類的機器模型\n",
    "4. 優化模型\n",
    "    1. 將模型進行訓練\n",
    "    2. 驗證模型的正確性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb90372-e213-406b-9eda-dba94d1fb8d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 參考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da31b7ea-4f2c-43bf-8d33-3565d5fad946",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 範例資料集\n",
    "\n",
    "* [Kaggle: Your Home for Data Science](https://www.kaggle.com/)  \n",
    "* [Gender Classification Dataset | Kaggle](https://www.kaggle.com/datasets/elakiricoder/gender-classification-dataset)\n",
    "* * *\n",
    "#### Python 觀念\n",
    "1. [Python基礎功不可少-dir()與help()的使用 @ 布萊恩的創業小窩的部落格 :: 痞客邦 ::](https://kobebrian5778.pixnet.net/blog/post/308583806-python%E5%9F%BA%E7%A4%8E%E5%8A%9F%E4%B8%8D%E5%8F%AF%E5%B0%91-dir%28%29%E8%88%87help%28%29%E7%9A%84%E4%BD%BF%E7%94%A8)\n",
    "2. [Python help() 函數 |  數字海洋](https://www.digitalocean.com/community/tutorials/python-help-function)  \n",
    "3. [Python enumerate() 函数 | 菜鸟教程](https://www.runoob.com/python/python-func-enumerate.html)  \n",
    "4. [How to Write Beautiful Python Code With PEP 8 – Real Python](https://realpython.com/python-pep8/#naming-styles)\n",
    "* * *\n",
    "#### Git 觀念\n",
    "1. [Git Commit Message Standard](https://gist.github.com/tonibardina/9290fbc7d605b4f86919426e614fe692)\n",
    "2. [Git Commit Message 這樣寫會更好，替專案引入規範與範例](https://wadehuanglearning.blogspot.com/2019/05/commit-commit-commit-why-what-commit.html)\n",
    "3. [Git - git-restore Documentation](https://git-scm.com/docs/git-restore)\n",
    "4. [菜鳥工程師 肉豬: Git 復原已staged的檔案 unstage changing Files](https://matthung0807.blogspot.com/2019/09/git-unstage-changing-files.html)\n",
    "5. [git操作之二：git restore - 良工说技术 - 博客园](https://www.cnblogs.com/teach/p/13997323.html)\n",
    "6. [檔案的四種狀態 · GIT教學](https://kingofamani.gitbooks.io/git-teach/content/chapter_2/repo.html)\n",
    "7. [檔案狀態 · Git](https://zlargon.gitbooks.io/git-tutorial/content/file/status.html)\n",
    "* * *\n",
    "#### PyTorch\n",
    "\n",
    "1. [Quickstart — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "2. [Datasets & DataLoaders — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "3. [Build the Neural Network — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "4. [Optimizing Model Parameters — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html)\n",
    "5. [Save and Load the Model — PyTorch Tutorials 1.13.1+cu117 documentation](https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html)\n",
    "* * *\n",
    "#### Markdown\n",
    "\n",
    "1. [如何建立表格 - HackMD](https://hackmd.io/c/tutorials-tw/%2Fs%2Fhow-to-create-table-tw)  \n",
    "2. [[教學] 撰寫 Hexo 文章 - Markdown 語法大全 | 瑪利歐的部落格](https://ed521.github.io/2019/08/hexo-markdown/)  \n",
    "3. [Markdown 表格 | 菜鸟教程](https://www.runoob.com/markdown/md-table.html)\n",
    "* * *\n",
    "#### ML 學習資源\n",
    "\n",
    "* 建議參考此網頁的 ML的整個訓練過程  \n",
    "[【Day 19】 Google ML - Lesson 5 - 接下來幾天作為範例的「訓練資料集介紹」、範例「資料集訓練前分析」(順便補上整個ML訓練流程，作為系列文章中的訓練階段參考) - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10217666?sc=rss.iron)  \n",
    "\n",
    "1. [零基礎自學深度學習 ：（一）神經網路基本架構. 筆者曾於Coursera觀看過臺灣大學資工系林軒田教授授課的「機器學習基石（Ma… | by Evan | Medium](https://evan-hsiao.medium.com/%E5%BE%9Ecoursera%E5%AD%B8%E7%BF%92%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-bd6bad6f5e14)\n",
    "2. [Day-21 實際重現神經元是可做到的嗎? Feed-Forward Neural Network Building - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10277989)\n",
    "3. [[Day 29] Deep learning -- 各種模型(i) - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10189072)\n",
    "4. [DAY18：激活函數 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10276865)\n",
    "5. [Day-19 PyTorch 怎麼讀取資料? Dataset and DataLoader - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10277163)\n",
    "6. [【12】新手容易忽略的 logit 與 loss 之間的搭配 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10272449)\n",
    "7. [機器/深度學習: 基礎介紹-損失函數(loss function) | by Tommy Huang | Medium](https://chih-sheng-huang821.medium.com/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E4%BB%8B%E7%B4%B9-%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-loss-function-2dcac5ebb6cb)\n",
    "8. [【Day 20】 Google ML - Lesson 6 - 使用損失函數(Loss Functions)來評估ML模型的好壞吧!  MSE, RMSE, Cross Entropy的計算方法與特性 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10218158)\n",
    "9. [Day 14 Optimizer大亂鬥 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10236554)\n",
    "10. [[機器學習ML NOTE]SGD, Momentum, AdaGrad, Adam Optimizer | by GGWithRabitLIFE | 雞雞與兔兔的工程世界 | Medium](https://medium.com/%E9%9B%9E%E9%9B%9E%E8%88%87%E5%85%94%E5%85%94%E7%9A%84%E5%B7%A5%E7%A8%8B%E4%B8%96%E7%95%8C/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92ml-note-sgd-momentum-adagrad-adam-optimizer-f20568c968db)\n",
    "11. [7 Types of Classification Algorithms](https://analyticsindiamag.com/7-types-classification-algorithms/)\n",
    "12. [【Day 18】 Google ML - Lesson 4 - 什麼是ML模型?訓練的目標? 回歸模型(Regression model), 分類模型(Classification model)的運算 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10217431)\n",
    "13. [【大數據小知識】什麼是分類模型 (Classification)？如何評估 (Evaluate) 分類模型？ | by 資料分析大小事 | Taiwanese in Data Science | Medium](https://medium.com/women-in-data-science-taipei/%E5%A4%A7%E6%95%B8%E6%93%9A%E5%B0%8F%E7%9F%A5%E8%AD%98-%E4%BB%80%E9%BA%BC%E6%98%AF%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B-classification-%E5%A6%82%E4%BD%95%E8%A9%95%E4%BC%B0-evaluate-%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B-a96143d9a493)\n",
    "14. [The Neural Network Zoo - The Asimov Institute](https://www.asimovinstitute.org/neural-network-zoo/)  \n",
    "15. [bearpaw/pytorch-classification: Classification with PyTorch.](https://github.com/bearpaw/pytorch-classification)  \n",
    "16. [Use PyTorch to train your image classification model | Microsoft Learn](https://learn.microsoft.com/en-us/windows/ai/windows-ml/tutorials/pytorch-train-model)  \n",
    "17. [主流的深度学习模型有哪些？ - 知乎](https://zhuanlan.zhihu.com/p/29769502)  \n",
    "18. [【機器學習從零到一】 Day3: Pytorch 介紹與範例 (cosmetics classification) | by PJ Wang | Medium](https://daniel820710.medium.com/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%BE%9E%E9%9B%B6%E5%88%B0%E4%B8%80-day3-pytorch-%E4%BB%8B%E7%B4%B9%E8%88%87%E7%AF%84%E4%BE%8B-cosmetics-classification-6e826fbce59b)  \n",
    "19. [【機器學習懶人包】從數據分析到模型整合，各種好用的演算法全都整理給你啦！ | TechOrange 科技報橘](https://buzzorange.com/techorange/2019/08/13/machine-learning-algorithm-collection/)  \n",
    "20. [機器學習入門——常用優化器(Optimizer)的種類與選擇 - 程式人生](https://www.796t.com/content/1545433422.html)\n",
    "21. [Day 02：撰寫第一支 Neural Network 程式 -- 阿拉伯數字辨識 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10191404)\n",
    "22. [[Day8]資料正規化(Normalization)與標準化(Standardization) - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10293893)\n",
    "23. [[Day 27] 機器學習常犯錯的十件事 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10279778)\n",
    "24. [[Day 3] 你真了解資料嗎？試試看視覺化分析吧！ - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10264416)\n",
    "25. [Day 6. 機器學習模型 - 學習的種類 - iT 邦幫忙::一起幫忙解決難題，拯救 IT 人的一天](https://ithelp.ithome.com.tw/articles/10295354)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ada81d-692d-43d9-8635-7394dd0f82a1",
   "metadata": {},
   "source": [
    "* ML的整個「訓練過程」：這裡以監督式學習(Supervised Learning)為例\n",
    "\n",
    "| 階段 | 要做的事情 | 簡介 |\n",
    "| :--: | :--: | -- |\n",
    "| (訓練前) | 決定資料集與分析資料 | 你想要預測的是什麼資料? 這邊需要先知道 example、label、features的概念。介紹可參考：[【Day 15】](https://ithelp.ithome.com.tw/articles/10215499)，而我們這次作為範例的訓練資料集介紹在[【Day 19】](https://ithelp.ithome.com.tw/articles/10217666)。 |\n",
    "| (訓練前) | 決定問題種類 | 依據資料，會知道是什麼類型的問題。regression problem(回歸問題)? classification problem(分類問題)? 此處可參考：[【Day 16】](https://ithelp.ithome.com.tw/articles/10216585)、與進階內容：[【Day 17】](https://ithelp.ithome.com.tw/articles/10215946) |\n",
    "| (訓練前) | 決定ML模型(ML models) | 依據問題的種類，會知道需要使用什麼對應的ML模型。回歸模型(Regression model)? 分類模型(Classification model)? 此處可參考：[【Day 18】](https://ithelp.ithome.com.tw/articles/10217431)，神經網路(neural network)? 簡介於：[【Day 25】](https://ithelp.ithome.com.tw/articles/10221227) |\n",
    "| | (模型裡面的參數) | ML模型裡面的參數(parameters)與超參數(hyper-parameters) 此處可參考：[【Day 18】](https://ithelp.ithome.com.tw/articles/10217431) |\n",
    "| (訓練中)<br>調整模型 | 評估當前模型好壞 | 損失函數(Loss Functions)：使用損失函數評估目前模型的好與壞。以MSE(Mean Squared Error), RMSE(Root Mean Squared Error), 交叉熵(Cross Entropy)為例。此處可參考：[【Day 20】](https://ithelp.ithome.com.tw/articles/10218158) |\n",
    "| (訓練中)<br>調整模型 | 修正模型參數 | 以梯度下降法 (Gradient Descent)為例：決定模型中參數的修正「方向」與「步長(step size)」此處可參考：[【Day 21】](https://ithelp.ithome.com.tw/articles/10218980) |\n",
    "| (訓練中)<br>調整腳步 | 調整學習腳步 | 透過學習速率(learning rate)來調整ML模型訓練的步長(step size)，調整學習腳步。(此參數在訓練前設定，為hyper-parameter)。此處可參考：[【Day 22】](https://ithelp.ithome.com.tw/articles/10219458) |\n",
    "| (訓練中)<br>加快訓練 | 取樣與分堆 | 設定batch size，透過batch從訓練目標中取樣，來加快ML模型訓練的速度。(此參數在訓練前設定，為hyper-parameter)。與迭代(iteration),epoch介紹。此處可參考：[【Day 23】](https://ithelp.ithome.com.tw/articles/10219945/draft) |\n",
    "| (訓練中)<br>加快訓練 | 檢查loss的頻率 | 調整「檢查loss的頻率」，依據時間(Time-based)與步驟(Step-based)。此處可參考：[【Day 23】](https://ithelp.ithome.com.tw/articles/10219945/draft) |\n",
    "| (訓練中)<br>完成訓練 | (loop) -> 完成 | 重覆過程(評估當前模型好壞 -> 修正模型參數)，直到能通過「驗證資料集(Validation)」的驗證即可結束訓練。此處可參考：[【Day 27】](https://ithelp.ithome.com.tw/articles/10222043) |\n",
    "| (訓練後) | 訓練結果可能問題 | 「不適當的最小loss?」 此處可參考：[【Day 28】](https://ithelp.ithome.com.tw/articles/10222317) |\n",
    "| (訓練後) | 訓練結果可能問題 | 欠擬合(underfitting)?過度擬合(overfitting)? 此處可參考：[【Day 26】](https://ithelp.ithome.com.tw/articles/10221245) |\n",
    "| (訓練後) | 評估 - 性能指標 | 性能指標(performance metrics)：以混淆矩陣(confusion matrix)分析，包含「Accuracy」、「Precision」、「Recall」三種評估指標。簡介於：[【Day 28】](https://ithelp.ithome.com.tw/articles/10222317)、詳細介紹於：[【Day 29】](https://ithelp.ithome.com.tw/articles/10222697) |\n",
    "| (訓練後) | 評估 - 新資料適用性 | 泛化(Generalization)：對於新資料、沒看過的資料的模型適用性。此處可參考：[【Day 26】](https://ithelp.ithome.com.tw/articles/10221245) |\n",
    "| (訓練後) | 評估 - 模型測試 | 使用「獨立測試資料集(Test)」測試? 使用交叉驗證(cross-validation)(又稱bootstrapping)測試? 此處可參考：[【Day 27】](https://ithelp.ithome.com.tw/articles/10222043) |\n",
    "| | (資料分堆的方式) | (訓練前) 依據上方「模型測試」的方法，決定資料分堆的方式：訓練用(Training)、驗證用(Validation)、測試用(Test)。此處可參考：[【Day 27】](https://ithelp.ithome.com.tw/articles/10222043) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565dc8c-6b5c-457c-9411-e1a3b443989c",
   "metadata": {},
   "source": [
    "# 解決分類問題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fc2e2-8444-43bb-bb4d-b942bec2f441",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0. 導入套件、設定初始參數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25de39b-0cfb-436b-9469-9af4b738e7f6",
   "metadata": {},
   "source": [
    "* 導入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad01b85-dafe-4533-9bf8-ff2d332cec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基礎套件\n",
    "import torch\n",
    "\n",
    "# 資料處理\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 模型建立\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fcc8a-9007-4e1e-8811-151e4e2034af",
   "metadata": {},
   "source": [
    "* 設定初始參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf24641-77ec-40b5-a2d5-7872768ccd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# 取得 gpu 或 cpu 設備進行模型訓練\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# CSV 檔案路徑\n",
    "csv_file_path = \"datasets/gender_classification_v7-fix.csv\"\n",
    "cut_pos = 3000 # 切分訓練集以及測試集的位置\n",
    "\n",
    "# 模型訓練參數\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09117859-9079-4233-aa5b-15f3312083df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. 讀取 CSV 資料並建立資料集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2dd385-db4a-4051-9a7b-e0889f20afc8",
   "metadata": {},
   "source": [
    "* 自定義資料集類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7270c9-09c9-45c0-9dae-caf37610644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繼承 Dataset 物件\n",
    "class CSVDataset(Dataset):\n",
    "    \n",
    "    # 進行物件的初始化\n",
    "    def __init__(self, csv_file: str, start: int=None, end: int=None):\n",
    "        # 使用 pandas 讀取檔案\n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(f\"讀取 \\\"{csv_file}\\\" 檔案\\n\")\n",
    "        \n",
    "        # 取得檔案首行的資訊作為標籤\n",
    "        self.label = tuple(df.columns)\n",
    "        print(\"此檔案的標籤為:\")\n",
    "        [print(l) for l in self.label]\n",
    "        \n",
    "        # 讀取檔案中資料的範圍\n",
    "        self.dataframe = df.iloc[start:end]\n",
    "        print(f\"\\n此資料集總共有 {len(self)} 個資料\")\n",
    "        print(f\"\\n前五項資料為:{self.dataframe.head(5)}\")\n",
    "        \n",
    "        # 將特徵與結果切割出來(結果為每個元素的最後數值)\n",
    "        size = len(self.dataframe.iloc[0])\n",
    "        self.feature = self.dataframe.iloc[:, :size-1]\n",
    "        self.result = self.dataframe.iloc[:, size-1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"取得資料集數量\"\"\"\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        搜尋索引值資料\n",
    "        會回傳 (特徵值, 結果) 的資料\n",
    "        其中特徵值會先轉換成 list 格式再轉換為 tensor 格式，讓其格式容易進行訓練以及驗證\n",
    "        \"\"\"\n",
    "        return torch.tensor(list(self.feature.iloc[idx])), torch.tensor(self.result.iloc[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27de4c-c9cc-4ebb-9ae6-2247819c74ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. 將資料轉換成 PyTorch 容易使用的資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae8144-4f42-41c5-ac45-a8a9f34939b3",
   "metadata": {},
   "source": [
    "* 建立資料集物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c7de7c-ef69-4cba-a99a-eca44df28c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "讀取 \"datasets/gender_classification_v7-fix.csv\" 檔案\n",
      "\n",
      "此檔案的標籤為:\n",
      "long_hair\n",
      "forehead_width_cm\n",
      "forehead_height_cm\n",
      "nose_wide\n",
      "nose_long\n",
      "lips_thin\n",
      "distance_nose_to_lip_long\n",
      "gender\n",
      "\n",
      "此資料集總共有 3000 個資料\n",
      "\n",
      "前五項資料為:   long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
      "0          1               11.8                 6.1          1          0   \n",
      "1          0               14.0                 5.4          0          0   \n",
      "2          0               11.8                 6.3          1          1   \n",
      "3          0               14.4                 6.1          0          1   \n",
      "4          1               13.5                 5.9          0          0   \n",
      "\n",
      "   lips_thin  distance_nose_to_lip_long  gender  \n",
      "0          1                          1       1  \n",
      "1          1                          0       0  \n",
      "2          1                          1       1  \n",
      "3          1                          1       1  \n",
      "4          0                          0       0  \n",
      "讀取 \"datasets/gender_classification_v7-fix.csv\" 檔案\n",
      "\n",
      "此檔案的標籤為:\n",
      "long_hair\n",
      "forehead_width_cm\n",
      "forehead_height_cm\n",
      "nose_wide\n",
      "nose_long\n",
      "lips_thin\n",
      "distance_nose_to_lip_long\n",
      "gender\n",
      "\n",
      "此資料集總共有 2001 個資料\n",
      "\n",
      "前五項資料為:      long_hair  forehead_width_cm  forehead_height_cm  nose_wide  nose_long  \\\n",
      "3000          1               13.7                 7.1          1          1   \n",
      "3001          1               12.7                 5.9          0          0   \n",
      "3002          0               13.7                 6.4          0          1   \n",
      "3003          1               13.3                 5.5          0          0   \n",
      "3004          1               11.6                 5.1          1          0   \n",
      "\n",
      "      lips_thin  distance_nose_to_lip_long  gender  \n",
      "3000          0                          1       1  \n",
      "3001          0                          1       0  \n",
      "3002          1                          0       0  \n",
      "3003          0                          0       0  \n",
      "3004          1                          1       1  \n"
     ]
    }
   ],
   "source": [
    "train_ds = CSVDataset(csv_file_path, end=cut_pos)\n",
    "test_ds = CSVDataset(csv_file_path, start=cut_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb4451b-b547-40d6-9c8e-8dbe364f8d28",
   "metadata": {},
   "source": [
    "* 使用 torch.utils.DataLoader 存取資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6164d394-0821-4a78-9984-e6e1b9b32e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109504cc-7590-4f30-ae44-d05728427008",
   "metadata": {},
   "source": [
    "### 3. 建立用於分類的機器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3028970-4784-4d6a-97d0-37cfdfee28ba",
   "metadata": {},
   "source": [
    "* 建立分類模型類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a640102d-aa30-4eda-bd05-1ff8ce8f2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNetwork(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_classes: int):\n",
    "        \"\"\"\n",
    "        input_size: 輸入大小\n",
    "        hidden_size: 隱藏層神經元數量\n",
    "        num_classes: 類別數量\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # 模型架構\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "        \n",
    "    # 前饋(向前傳播)\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb7070-6275-4444-9f7f-57268939c5ae",
   "metadata": {},
   "source": [
    "* 建立模型物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc71c30-82e9-4797-b24f-403d93bf04c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=512, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_model = ClassifierNetwork(len(train_dataloader.dataset.label)-1, 512, 2).to(device)\n",
    "c_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2895c51c-bb5e-4f26-91af-0eb63dc063d6",
   "metadata": {},
   "source": [
    "* 建立優化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e44d82e-4cd8-4846-8cc6-9c4ecfea8ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(c_model.parameters(), lr=learning_rate)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03edcbc-6b05-4d8f-b8ca-ee16cdebaa5f",
   "metadata": {},
   "source": [
    "* 訓練模型函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd59a97-f3e1-4463-b723-636885986fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader: DataLoader, model: nn.Module, loss_fn: nn.modules.loss, optimizer: torch.optim.Optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 選擇硬體設備進行運算\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Compute prediction error(計算預測誤差)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation(反向傳播)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c09c7a-2b0d-44e4-bd6b-8808f83feb19",
   "metadata": {},
   "source": [
    "* 驗證模型函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc2c8be-9cc2-4392-bba9-15921322f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader: DataLoader, model: nn.Module, loss_fn: nn.modules.loss):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad(): # 禁用梯度運算\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f423bd-7db5-4b0e-be64-8833403937fd",
   "metadata": {},
   "source": [
    "* 進行訓練以及驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bea5de7-1fe4-4fda-a08e-058e94b21cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.691104 [    0/ 3000]\n",
      "loss: 0.692475 [  640/ 3000]\n",
      "loss: 0.685127 [ 1280/ 3000]\n",
      "loss: 0.695479 [ 1920/ 3000]\n",
      "loss: 0.696869 [ 2560/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.684603 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.680588 [    0/ 3000]\n",
      "loss: 0.686245 [  640/ 3000]\n",
      "loss: 0.682371 [ 1280/ 3000]\n",
      "loss: 0.681705 [ 1920/ 3000]\n",
      "loss: 0.678141 [ 2560/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.678669 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.677064 [    0/ 3000]\n",
      "loss: 0.675291 [  640/ 3000]\n",
      "loss: 0.677761 [ 1280/ 3000]\n",
      "loss: 0.671975 [ 1920/ 3000]\n",
      "loss: 0.671960 [ 2560/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.671678 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.670765 [    0/ 3000]\n",
      "loss: 0.671354 [  640/ 3000]\n",
      "loss: 0.665937 [ 1280/ 3000]\n",
      "loss: 0.666057 [ 1920/ 3000]\n",
      "loss: 0.666757 [ 2560/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 0.667729 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.672347 [    0/ 3000]\n",
      "loss: 0.665191 [  640/ 3000]\n",
      "loss: 0.661467 [ 1280/ 3000]\n",
      "loss: 0.660427 [ 1920/ 3000]\n",
      "loss: 0.661351 [ 2560/ 3000]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.660029 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, c_model, loss_fn, optimizer)\n",
    "    test(test_dataloader, c_model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9bb9e-651d-4788-992b-0fc5b5837761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
