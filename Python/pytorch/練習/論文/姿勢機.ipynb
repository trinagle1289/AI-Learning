{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c64f2f4-14bb-40f9-ab6d-80cd4ae02a86",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 導入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16d18ff-423b-4097-98c9-8cffd87a4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要套件\n",
    "import torch\n",
    "\n",
    "# 資料處理\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 建立機器模型\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43b90f-1331-4796-b013-df9a6ab8889c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. 修正參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b21f40-d1f5-46e7-b723-407a80f52f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 擷取資料檔案\n",
    "gesture_data_file = \"dataset/train_data-x_y.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f699684b-3b64-4397-b1ab-6ff63692cb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# 取得 GPU 或是 CPU 的設備進行訓練\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be8f8729-0b45-408f-a6d7-befc4755e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批次\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f601fa10-dee4-46dc-ac23-83ec8a9fdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 優化函數\n",
    "optim_fn = optim.SGD\n",
    "# 損失函數\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14aab475-8ed6-4b2f-81a7-2cc9b7334bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 學習率\n",
    "learning_rate = 1e-5\n",
    "# 世代\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e5f45-0729-440a-99f1-61297c65282b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. 類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb30621-9164-4d6a-bf74-1ca76e6abe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 姿態資料集\n",
    "class GestureDataset(Dataset):\n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.dataframe = df\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 取得資料特徵，轉換成 torch 格式，資料為 torch.float32 格式\n",
    "        feature = torch.tensor(self.dataframe.iloc[idx, :-1]).to(torch.float32)\n",
    "        # 取得結果\n",
    "        result = self.dataframe.iloc[idx, -1]\n",
    "        return feature, result\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41027644-9e90-443f-bb04-831b16c6510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 姿態模型\n",
    "class GestureModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.relu_linear_stack = nn.Sequential(\n",
    "            nn.Linear(34, 68),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(68, 4)\n",
    "        )\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.relu_linear_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f77cd-6194-4e13-8c7d-f9d1c74ccf65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. 函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051328d5-21bd-42c2-9ea9-177172ab5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練函數\n",
    "def train(dataloader:DataLoader, model:nn.Module, loss_fn:torch.nn.modules.Module, optimizer:optim.Optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # 開始訓練\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 轉換成可讓模型訓練的格式\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # 計算預測誤差\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation 反向傳播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 輸出\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch+1)*len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cb31004-ce96-4e40-9059-5e1959d9e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試函數\n",
    "def test(dataloader:DataLoader, model:nn.Module, loss_fn:torch.nn.modules.Module):\n",
    "    \n",
    "    # 計算結果參數\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    # 測試誤差、正確率\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # 開始驗證\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # 轉換成可讓模型訓練的格式\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 計算預測誤差\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            # 計算誤差、正確率\n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3083512e-b80c-4892-83ae-7650972dda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輔助函式\n",
    "from playsound import playsound\n",
    "# 撥放音樂\n",
    "def PlaySound():\n",
    "    sound_pth = \"E:\\Media Cabinet\\Musics\\Musics\\dio zawaruto.mp3\"\n",
    "    playsound(sound_pth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386f192-22f5-4889-a681-ef780e801ba9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. 使用資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77471f17-38ae-4cf3-b87e-055cf2aa4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 csv 資料\n",
    "gesture_df = pd.read_csv(gesture_data_file)\n",
    "\n",
    "# 切分成訓練以及測試資料\n",
    "train_df = gesture_df.iloc[::3]\n",
    "test_df = gesture_df.iloc[1::2]\n",
    "\n",
    "# 建立資料集\n",
    "train_dataset = GestureDataset(train_df)\n",
    "test_dataset = GestureDataset(test_df)\n",
    "\n",
    "# 建立加載器\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8488f10-90ab-4b29-8242-6461cef986ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687137e5-1541-4368-adbd-88f945d6206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GestureModel(\n",
       "  (relu_linear_stack): Sequential(\n",
       "    (0): Linear(in_features=34, out_features=68, bias=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=68, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立模型\n",
    "model = GestureModel().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b478d66-3712-42aa-bd15-02357ed1d923",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 7. 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d8eead1-a316-41dc-80af-20608bd4e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 144.908508 [    1/ 1179]\n",
      "loss: 1.334924 [  101/ 1179]\n",
      "loss: 1.313964 [  201/ 1179]\n",
      "loss: 1.324589 [  301/ 1179]\n",
      "loss: 1.518091 [  401/ 1179]\n",
      "loss: 1.274994 [  501/ 1179]\n",
      "loss: 1.269107 [  601/ 1179]\n",
      "loss: 1.258041 [  701/ 1179]\n",
      "loss: 1.526520 [  801/ 1179]\n",
      "loss: 1.228295 [  901/ 1179]\n",
      "loss: 1.211085 [ 1001/ 1179]\n",
      "loss: 1.195195 [ 1101/ 1179]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 1.337786 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.188890 [    1/ 1179]\n",
      "loss: 1.575583 [  101/ 1179]\n",
      "loss: 1.499029 [  201/ 1179]\n",
      "loss: 1.499999 [  301/ 1179]\n",
      "loss: 1.147133 [  401/ 1179]\n",
      "loss: 1.515099 [  501/ 1179]\n",
      "loss: 1.133888 [  601/ 1179]\n",
      "loss: 1.524607 [  701/ 1179]\n",
      "loss: 1.110009 [  801/ 1179]\n",
      "loss: 1.104809 [  901/ 1179]\n",
      "loss: 1.617682 [ 1001/ 1179]\n",
      "loss: 1.551447 [ 1101/ 1179]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 1.319167 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.077382 [    1/ 1179]\n",
      "loss: 1.634186 [  101/ 1179]\n",
      "loss: 1.065218 [  201/ 1179]\n",
      "loss: 1.065003 [  301/ 1179]\n",
      "loss: 1.636797 [  401/ 1179]\n",
      "loss: 1.046028 [  501/ 1179]\n",
      "loss: 1.647350 [  601/ 1179]\n",
      "loss: 1.598146 [  701/ 1179]\n",
      "loss: 1.604321 [  801/ 1179]\n",
      "loss: 1.603414 [  901/ 1179]\n",
      "loss: 1.011301 [ 1001/ 1179]\n",
      "loss: 1.403183 [ 1101/ 1179]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 1.309781 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.399520 [    1/ 1179]\n",
      "loss: 1.000603 [  101/ 1179]\n",
      "loss: 1.399800 [  201/ 1179]\n",
      "loss: 1.395784 [  301/ 1179]\n",
      "loss: 0.988031 [  401/ 1179]\n",
      "loss: 1.688529 [  501/ 1179]\n",
      "loss: 1.403141 [  601/ 1179]\n",
      "loss: 1.399610 [  701/ 1179]\n",
      "loss: 1.706069 [  801/ 1179]\n",
      "loss: 0.959813 [  901/ 1179]\n",
      "loss: 1.413924 [ 1001/ 1179]\n",
      "loss: 0.955805 [ 1101/ 1179]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m PlaySound() \u001b[38;5;66;03m# 完成訓練後撥放音樂\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# 轉換成可讓模型訓練的格式\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;66;03m# 計算預測誤差\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         pred \u001b[38;5;241m=\u001b[39m model(X)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "optimizer = optim_fn(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(train_dataloader, model, loss_fn)\n",
    "    \n",
    "print(\"Done!\")\n",
    "PlaySound() # 完成訓練後撥放音樂"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
